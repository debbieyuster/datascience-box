---
title: "Linear models with a single predictor <br> `r emo::ji('dango')`"
author: ""
output:
  xaringan::moon_reader:
    css: "../slides.css"
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
---

```{r child = "../setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(broom)
library(here)
```


## Recall: The Paris Paintings dataset

```{r load-pp, message=FALSE}
pp <- read_csv(
  "data/paris-paintings.csv", 
  na = c("n/a", "", "NA")
  )
```

--

### Height & width

.small[
```{r}
m_ht_wt <- lm(Height_in ~ Width_in, data = pp)
tidy(m_ht_wt)
```
]

$$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$

---

class: middle

# Prediction with models

---

## Predict height from width

.question[
On average, how tall are paintings that are 60 inches wide?  
$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$
]

--

```{r}
3.62 + 0.78 * 60
```

--

"On average, we expect paintings that are 60 inches wide to be 50.42 inches high."

--

**Warning:** We "expect" this to happen, but there will be some variability. 
(We'll learn about measuring the variability around the prediction later.)

---

## Prediction in R

Use the `predict()` function to make a prediction:

- First argument: model
- Second argument: data frame representing the new observation(s) for which 
you want to make a prediction, with variables having the same names as those 
used to build the model, except for the response variables

---

## Prediction in R (cont.)

- Making a prediction for a single new observation:
```{r oredict-single-new}
newpainting <- tibble(Width_in = 60)
predict(m_ht_wt, newdata = newpainting)
```

- Making a prediction for multiple new observations:
```{r oredict-multiple-new}
newpaintings <- tibble(Width_in = c(50, 60, 70))
predict(m_ht_wt, newdata = newpaintings)
```

---

## Prediction vs. extrapolation

.question[
On average, how tall are paintings that are 400 inches wide?
$$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$
]

```{r extrapolate, warning = FALSE, echo=FALSE, out.width = "80%"}
newdata <- tibble(Width_in = 400)
newdata <- newdata %>%
  mutate(Height_in = predict(m_ht_wt, newdata = newdata))

ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", fullrange = TRUE, color = "#A7D5E8", se = FALSE) +
  xlim(0, 420) +
  ylim(0, 320) +
  geom_segment(data = newdata, mapping = aes(x = Width_in, y = 0, xend = Width_in, yend = Height_in), color = "#1E5C65", lty = 2) +
  geom_segment(data = newdata, mapping = aes(x = Width_in, y = Height_in, xend = 0, yend = Height_in), color = "#1E5C65", lty = 2)
```

---

## Watch out for extrapolation!

> "When those blizzards hit the East Coast this winter, it proved to my satisfaction 
that global warming was a fraud. That snow was freezing cold. But in an alarming 
trend, temperatures this spring have risen. Consider this: On February 6th it was 10 
degrees. Today it hit almost 80. At this rate, by August it will be 220 degrees. So 
clearly folks the climate debate rages on."<sup>1</sup>  <br>
Stephen Colbert, April 6th, 2010

.footnote[
[1] OpenIntro Statistics. "Extrapolation is treacherous." OpenIntro Statistics.
]

---

class: middle

# Measuring model fit

---

## Measuring the strength of the fit

- The strength of the fit of a linear model is most commonly evaluated using $R^2$.
- It tells us what percent of variability in the response variable is explained by 
the model.
- The remainder of the variability is explained by variables not included in the 
model.

---

## Height vs. landscape features

.question[
Which of the following is the correct interpretation of $R^2$ of the model 
below?
]

.small[
```{r}
m_ht_lands <- lm(Height_in ~ factor(landsALL), data = pp)
glance(m_ht_lands)$r.squared
```
]

**(a)** 3.5% of the variability in heights of paintings can be explained by 
whether or not the painting has landscape features.

**(b)** 3.5% of the variability in whether a painting has landscape features 
can be explained by heights of paintings.

**(c)** This model predicts 3.5% of heights of paintings accurately.

**(d)** This model predicts 3.5% of whether a painting has landscape features 
accurately.

**(e)** 3.5% of the time there is an association between whether a painting 
has landscape features and its height.

---

## Height vs. width

.small[
```{r}
glance(m_ht_wt)
glance(m_ht_wt)$r.squared # extract R-squared
```
]

Roughly 68% of the variability in heights of paintings can be explained by their
widths.

---

class: middle

# Tidy regression output

---

## Not-so-tidy regression output

- You might come across these in your googling adventures, but we'll try to stay away from them
- Not because they are wrong, but because they don't result in tidy data frames as results.

---

## Not-so-tidy regression output (1)

#### Option 1:

```{r}
m_ht_wt
```

---

## Not-so-tidy regression output (2)

#### Option 2:

.small[
```{r}
summary(m_ht_wt)
```
]

---

## Review

.question[
What makes a data frame tidy?
]

--
- Each variable forms a column.
- Each observation forms a row.
- Each type of observational unit forms a table.

---

## Tidy regression output

Achieved with functions from the `broom` package:

- `tidy`: Constructs a data frame that summarizes the model's statistical findings: coefficient estimates, *standard errors, test statistics, p-values*.
- `glance`: Constructs a concise one-row summary of the model. This typically contains values such as $R^2$, adjusted $R^2$, *and residual standard error that are computed once for the entire model*.
- `augment`: Adds columns to the original data that was modeled. This includes predictions and residuals.

---

## We've already seen...

- Tidy your model's statistical findings

.small[
```{r}
tidy(m_ht_wt)
```
]

- Glance to assess model fit

.small[
```{r}
glance(m_ht_wt)
```
]

---

## Augment data with model results

New variables of note (for now):

- `.fitted`: Predicted value of the response variable
- `.resid`: Residuals

.small[
```{r}
augment(m_ht_wt) %>%
  slice(1:5)
```
]

--

.question[
Why might we be interested in these new variables?
]

---

## Residuals plot

.small[
```{r out.width = "80%"}
m_ht_wt_aug <- augment(m_ht_wt)
ggplot(m_ht_wt_aug, mapping = aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted height", y = "Residuals")
```
]

---

class: middle

# Model checking

---

## "Linear" models

- We're fitting a "linear" model, which assumes a linear relationship between 
our explanatory and response variables.
- But how do we assess this?

---

## Looking for...

- Residuals distributed randomly around 0
- With no visible pattern along the x or y axes

```{r out.width = "80%", echo=FALSE}
set.seed(12346)
df <- tibble(
  fake_resid = rnorm(1000, mean = 0, sd = 30),
  fake_predicted = runif(1000, min = 0, max = 200)
)
ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted", y = "Residuals")
```

---

## Not looking for...

### Fan shapes

```{r out.width = "80%", echo=FALSE}
set.seed(12346)
df <- tibble(
  fake_resid = c(rnorm(100, mean = 0, sd = 1), 
                 rnorm(100, mean = 0, sd = 15), 
                 rnorm(100, mean = 0, sd = 25), 
                 rnorm(100, mean = 0, sd = 20), 
                 rnorm(100, mean = 0, sd = 25), 
                 rnorm(100, mean = 0, sd = 50), 
                 rnorm(100, mean = 0, sd = 35), 
                 rnorm(100, mean = 0, sd = 40),
                 rnorm(200, mean = 0, sd = 80)),
  fake_predicted = seq(0.2, 200, 0.2)
)
ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted", y = "Residuals")
```

---

## Not looking for...

### Residuals correlated with predicted values

```{r out.width = "80%", echo=FALSE}
set.seed(12346)
df <- tibble(
  fake_predicted = seq(0.2, 200, 0.2),
  fake_resid = c(
    rnorm(500, mean = -20, sd = 10),
    rnorm(500, mean = 10, sd = 10)
  )
)
ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted", y = "Residuals")
```

---

## Not looking for...

### Groups of patterns

```{r out.width = "80%", echo=FALSE}
set.seed(12346)
df <- tibble(
  fake_predicted = seq(0.2, 200, 0.2),
  fake_resid = fake_predicted + rnorm(1000, mean = 0, sd = 50)
)
ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted", y = "Residuals")
```

---

## Not looking for...

### Any patterns!

```{r out.width = "80%", echo=FALSE}
set.seed(12346)
df <- tibble(
  fake_predicted = seq(-100, 100, 0.4),
  fake_resid = -5*fake_predicted^2 - 3*fake_predicted + 20000 + rnorm(501, mean = 0, sd = 10000)
)
ggplot(df, mapping = aes(x = fake_predicted, y = fake_resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted", y = "Residuals")
```

---

.question[
What patterns does the residuals plot reveal that should make us question 
whether a linear model is a good fit for modeling the relationship 
between height and width of paintings?
]

```{r out.width = "80%", echo=FALSE}
ggplot(m_ht_wt_aug, mapping = aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "gray", lty = 2) +
  labs(x = "Predicted height", y = "Residuals")
```
